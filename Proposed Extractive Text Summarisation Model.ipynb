{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014a53b3-b59c-4b8f-b4d0-05705d6b216a",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a9bdd5-ea65-4e92-9a53-6377378c4ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import transformers\n",
    "# from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from rouge import Rouge\n",
    "\n",
    "# import datasets\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10bdca6-6faf-4672-bb8f-656223f24534",
   "metadata": {},
   "source": [
    "# Load JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6729350e-074c-48dc-90df-a09c2cf1d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wikihow_trimmed.json','r',encoding='utf-8') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f1de8-5fc2-4809-8e6d-09479bdeeef3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1da0479-c690-4200-85e7-63abb72cebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumExtractorModel(nn.Module):\n",
    "    def __init__(self, dim_in, dim_hid, dim_out, num_layers,num_head, dropout=0.5):\n",
    "        super(SumExtractorModel,self).__init__()\n",
    "                \n",
    "        assert dim_in % num_head == 0 #Check if input dimension is divisible by the number of attention heads\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(dim_in, nhead=num_head, dim_feedforward=dim_hid, device=device,dropout=dropout)\n",
    "        \n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer,num_layers)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(dim_in*dim_out, dim_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_hid, dim_out),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_sent, attention_mask=None):\n",
    "        \n",
    "        # Get embeddings from pretrained model\n",
    "        embeddings = input_sent\n",
    "        bs, seq_len, embed_dim = embeddings.shape\n",
    "        embeddings = embeddings.permute(1,0,2) #Switch from (batch, seq_len, embed_dim) -> (seq_len, batch, embed_dim)\n",
    "        # embeddings = self.pretrained_model.encode(input_sent)\n",
    "        # print(embeddings.shape)\n",
    "        \n",
    "        # Normalize embeddings        \n",
    "        output = self.encoder(embeddings,attention_mask)\n",
    "        # print(\"After Encoder: \",output.shape)\n",
    "        output = output.view(bs,-1)\n",
    "        # print(\"After Reshape: \",output.shape)\n",
    "        output = self.classifier(output)\n",
    "        # print(\"After Classifier: \",output.shape)\n",
    "\n",
    "        # raise \"stop here\"\n",
    "        return output #Output after a Sigmoid activation, to use with BCELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c60a8e-a98c-4172-b8c3-04c1e62d1614",
   "metadata": {},
   "source": [
    "# Train Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b771bc3f-a7bf-4602-aac1-2feebcad8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = data['max_length']\n",
    "dim_in = 384 #For MiniLM-L6-v2 .Size of embeddings given by pre-trained model, depends on output of pretrained model dimensions\n",
    "# dim_in = 768 #For distilroberta\n",
    "dim_hid = 256\n",
    "encoder_layers = 3\n",
    "num_heads = 4 #Attention heads\n",
    "\n",
    "# num_iters = 15\n",
    "num_iters = 20000 #Iterations per epoch\n",
    "num_epochs = 10\n",
    "\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76d124e-954c-4117-912f-60ee622a37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# pretrained_name = \"sentence-transformers/all-distilroberta-v1\"\n",
    "\n",
    "pretrained_model = SentenceTransformer(pretrained_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b7cbdf-4b40-4126-a683-08fb2c6aac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SumExtractorModel(dim_in, dim_hid, max_length, encoder_layers, num_heads).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = lr)\n",
    "loss_function = nn.BCELoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74569f-1285-4aaa-af22-d9538d428606",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684b8965-91b8-493d-a520-773f06275c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, model, loss_fct, optimizer,mask=None):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    inputs = input_tensor\n",
    "    targets = target_tensor\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(inputs,mask)\n",
    "\n",
    "    loss = loss_fct(output,targets)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cur_los = loss.item()\n",
    "    \n",
    "    return cur_los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6af8541-a129-489c-be6d-700403eb4dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(input_tensor, target_tensor, model, loss_fct,mask=None):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    inputs = input_tensor\n",
    "    targets = target_tensor\n",
    "\n",
    "    output = model(inputs,mask)\n",
    "\n",
    "    loss = loss_fct(output,targets)\n",
    "    val_los = loss.item()\n",
    "    \n",
    "    return val_los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb42fa4e-4ba6-47d9-bac5-46a1b9515069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testset, model, rouge):\n",
    "    \n",
    "    rouge1 = []\n",
    "    rouge2 = []\n",
    "    rougel = []\n",
    "    sum_len = 4 #How many sentences to use as summary from model output\n",
    "    model.eval()\n",
    "    i=1\n",
    "    target = random.randint(2000,4000)\n",
    "    \n",
    "    for testpair in tqdm(testset,position =0, desc='Rouge Testing'):\n",
    "        sentence, _, = getEmbed(testpair[0],testpair[1], data['max_length'], pretrained_model)\n",
    "        sentence = sentence.to(device)\n",
    "        \n",
    "        orig_len = len(testpair[0])\n",
    "        tgt_sum = [testpair[0][i] for i in range(len(testpair[1])) if testpair[1][i] == 1]\n",
    "        tgt_sum = [' '.join(tgt_sum)]\n",
    "        \n",
    "        hyp = model(sentence).squeeze()[:orig_len] #Trim away excess output from padding\n",
    "        \n",
    "        if len(hyp) < sum_len:\n",
    "            #If unable to get 4 sentences just get the highest number available.\n",
    "            hyp = torch.topk(hyp,len(hyp))[1].detach().cpu().numpy()\n",
    "        else:\n",
    "            #Get top 4 sentences to use for summary.\n",
    "            hyp = torch.topk(hyp,sum_len)[1].detach().cpu().numpy()\n",
    "        \n",
    "        hyp = sorted(hyp)\n",
    "        hyp = [testpair[0][i] for i in hyp]\n",
    "        hyp = [' '.join(hyp)]\n",
    "        \n",
    "        if i == target:\n",
    "            print(f\"Model Output: {hyp}\")\n",
    "            print()\n",
    "            print(f\"Actual Summary: {tgt_sum}\")\n",
    "            print()\n",
    "            print(i)\n",
    "        \n",
    "        score = rouge.get_scores(hyp, tgt_sum,avg=True)\n",
    "        rouge1.append(score['rouge-1']['f'])\n",
    "        rouge2.append(score['rouge-2']['f'])\n",
    "        rougel.append(score['rouge-l']['f'])\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    print(\"====Rouge Scores Below====\")\n",
    "    print(f\"Rouge-1 Score: {np.mean(rouge1)}\")\n",
    "    print(f\"Rouge-2 Score: {np.mean(rouge2)}\")\n",
    "    print(f\"Rouge-l Score: {np.mean(rougel)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e4c0031-0e0c-4092-bc95-cf2d712cd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbed(source, target, maxlen, model):\n",
    "    pad_token = '[PAD]'\n",
    "    sentences = source\n",
    "    labels = target\n",
    "    orig_len = len(source)\n",
    "    \n",
    "    if len(sentences) < maxlen:\n",
    "        pad_num = maxlen - len(sentences)\n",
    "        sentences = sentences + [pad_token for i in range(pad_num)]\n",
    "        labels = labels + [0 for i in range(pad_num)]\n",
    "             \n",
    "    output = model.encode(sentences)\n",
    "    output = torch.tensor(output,dtype=torch.float32).unsqueeze(0)\n",
    "    labels = torch.tensor(labels,dtype=torch.float32).unsqueeze(0)\n",
    "#     mask = torch.zeros((maxlen,maxlen), dtype=torch.float32)\n",
    "    \n",
    "#     for i in range(maxlen):\n",
    "#         for j in range(maxlen):\n",
    "#             if (j < orig_len) and (i < orig_len):\n",
    "#                 mask[i][j] = 1.0\n",
    "    \n",
    "    return output, labels# , mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a0fbd23-b9a6-4b52-a67b-06a7d36719f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc51dccc7f9492abd1490d699959072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b5ba9c098b4bf6926ec5e485ac2b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1, Train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1091239801120013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f71f7ef9427455b89ec72b14803eb89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1, Validation:   0%|          | 0/5543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Model saved** New best validation loss: 0.16882556703277019\n",
      "Validation loss: 0.16882556703277019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc74236944346fca54febfa9f206a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2, Train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10247664355374873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3b0434c4e1450ab5ec2504804e4258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2, Validation:   0%|          | 0/5543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Model saved** New best validation loss: 0.1282325627142135\n",
      "Validation loss: 0.1282325627142135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3dd66f798b44e9825e4ebccbdc45d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3, Train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10023083524005487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cdb80914944b4f81d61211295a171d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3, Validation:   0%|          | 0/5543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Model saved** New best validation loss: 0.12094052935910637\n",
      "Validation loss: 0.12094052935910637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6799d53e5e441adac485986959c2b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4, Train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.099416930958163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44f5a4baae14fb2bacf7f9793480cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4, Validation:   0%|          | 0/5543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Model saved** New best validation loss: 0.1144787656022671\n",
      "Validation loss: 0.1144787656022671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c072c956a1404e2fb5223e35d4ee9107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5, Train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1045500708853826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1231fff6469f46f89df8401b9c230bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5, Validation:   0%|          | 0/5543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.11489556273322835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2114aef688f2430484ee8bf32bd86a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6, Train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09984934172555804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ab20f5deba4c8aa239746511fe0804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6, Validation:   0%|          | 0/5543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Model saved** New best validation loss: 0.11360214592395987\n",
      "Validation loss: 0.11360214592395987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8c692dadb04feba1ff8b0fb9460677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7, Train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09830715311709791\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8620e76677e74561a0632672e267866a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7, Validation:   0%|          | 0/5543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.11442446409069887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a722177c994e6e9ef32478b661f4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8, Train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0991067492838949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9738215e8646e3a2506eb9bc468483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8, Validation:   0%|          | 0/5543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.11863741799033056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a012549eca4907be873f7b4ff3fd06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9, Train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10385441885134206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf5456689d840de9d11d8e0cfa9a3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9, Validation:   0%|          | 0/5543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Model saved** New best validation loss: 0.11151248142768411\n",
      "Validation loss: 0.11151248142768411\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c21f12c4ee475e9721d440deee3ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10, Train:   0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.10434386999038979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e51e44cfbcb43f6af4f1bea2844b437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10, Validation:   0%|          | 0/5543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Model saved** New best validation loss: 0.10886168674248801\n",
      "Validation loss: 0.10886168674248801\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "\n",
    "for e in tqdm(range(1,num_epochs+1), position=0, desc='Epoch'):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    \n",
    "    train_set = [random.choice(data['train']) for _ in range(num_iters)]\n",
    "    \n",
    "    #Training\n",
    "    for i in tqdm(range(1,num_iters+1), desc=f'Epoch {e}, Train', position = 1):\n",
    "        pair = train_set[i-1]\n",
    "\n",
    "        # input_tensor, target_tensor, mask = getEmbed(pair[0],pair[1], data['max_length'], pretrained_model)\n",
    "        # input_tensor, target_tensor, mask = input_tensor.to(device), target_tensor.to(device), mask.to(device)\n",
    "        \n",
    "        input_tensor, target_tensor = getEmbed(pair[0],pair[1], data['max_length'], pretrained_model)\n",
    "        input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
    "        \n",
    "        train_iter_loss = train(input_tensor, target_tensor, model, loss_function, optimizer,mask)\n",
    "        \n",
    "        train_loss.append(train_iter_loss)\n",
    "        \n",
    "    print(f\"Train loss: {np.mean(train_loss)}\")\n",
    "        \n",
    "    #Validation\n",
    "    for val_pair in tqdm(data['val'],position=2,desc=f'Epoch {e}, Validation'):\n",
    "    \n",
    "        # input_tensor, target_tensor, mask = getEmbed(val_pair[0],val_pair[1], data['max_length'], pretrained_model)\n",
    "        # input_tensor, target_tensor, mask = input_tensor.to(device), target_tensor.to(device), mask.to(device)\n",
    "    \n",
    "        input_tensor, target_tensor = getEmbed(val_pair[0],val_pair[1], data['max_length'], pretrained_model)\n",
    "        input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
    "    \n",
    "        val_iter_loss = validation(input_tensor, target_tensor, model, loss_function,mask)\n",
    "        val_loss.append(val_iter_loss)\n",
    "    \n",
    "    if (not best_val_loss) or (np.mean(val_loss) < best_val_loss):\n",
    "        best_val_loss = np.mean(val_loss)\n",
    "        torch.save(model.state_dict(), f\"./model_weights/bestmodel{e}.pth\")\n",
    "        print(f\"**Model saved** New best validation loss: {best_val_loss}\")\n",
    "        \n",
    "    print(f\"Validation loss: {np.mean(val_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d664027-8472-43e5-9d12-e5ef314dbf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"simpletransformer.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9dfd0-9fc7-4b00-8b64-d2bbef0c195b",
   "metadata": {},
   "source": [
    "# Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bce0e1af-d549-47a6-8917-8192f8a3ce93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "model.load_state_dict(torch.load(\"./model_weights/3layer_4head/bestmodel8.pth\")) #Used to load model state dict of saved model.\n",
    "# model.load_state_dict(torch.load(\"./model_weights/distilroberta_3layer_4head/bestmodel10.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98d1b729-fd1d-409f-8e20-b2d1339d6fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2273647351f414bb459f7a246a83430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rouge Testing:   0%|          | 0/5502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Rouge Scores Below====\n",
      "Rouge-1 Score: 0.37598216423969455\n",
      "Rouge-2 Score: 0.21010031050480532\n",
      "Rouge-l Score: 0.3517201756941423\n"
     ]
    }
   ],
   "source": [
    "test(data['test'], model, rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91489e98-5a99-403a-8c4a-762f3cd21d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab114401-afd0-4316-8502-e143bce44ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a36bdb4cb3492b9020ee9e077b071c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rouge Testing:   0%|          | 0/5502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output: ['In order to make dopamine , your body needs tyrosine -- after a bunch of synthesizing and technical terms , it gets turned into your happy fuel . It can be found in soy products ( like tofu , etc . ) , fish , dairy , and meats . However , many dairy and meat products are high in calories and fat , so exercise caution and monitor your caloric intake with this high - dopamine diet . Dopamine is easy to oxidize , and antioxidants may reduce free radical damage to the brain cells that produce dopamine .']\n",
      "\n",
      "Actual Summary: ['In order to make dopamine , your body needs tyrosine -- after a bunch of synthesizing and technical terms , it gets turned into your happy fuel . Many fruits and vegetables are rich in antioxidants , including : Beta - carotene and carotenoids : Greens , orange vegetables and fruits , asparagus , broccoli , beets   Vitamin C : Peppers , oranges , strawberries , cauliflower ,']\n",
      "====Rouge Scores Below====\n",
      "Rouge-1 Score: 0.3860141396670621\n",
      "Rouge-2 Score: 0.21895983530453486\n",
      "Rouge-l Score: 0.3611139557144689\n"
     ]
    }
   ],
   "source": [
    "test(data['test'], model, rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a5c5b5-d2a6-4a99-b0ab-7348a4b34144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model contains 24028496 parameters\n"
     ]
    }
   ],
   "source": [
    "trainable_param = 0\n",
    "\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:\n",
    "        trainable_param += param.numel()\n",
    "        \n",
    "print(f\"Model contains {trainable_param} parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
